{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Spark Kafka Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://static.wixstatic.com/media/f17a52_84852646da5a4e37837a12cb610b2ad8~mv2.png/v1/fill/w_1000,h_673,al_c,usm_0.66_1.00_0.01/f17a52_84852646da5a4e37837a12cb610b2ad8~mv2.png)\n",
    "[Source](https://www.dataneb.com/post/analyzing-twitter-texts-spark-streaming-example-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"jumbotron\">\n",
    "    <center>\n",
    "        <b>Sentiment Analysis</b> of streaming twitter data using Flume/Kafka/Spark\n",
    "    </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://i.imgflip.com/40j9cu.jpg)\n",
    "[NicsMeme](https://imgflip.com/i/40j9cu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Workflow Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 1) Model Building\n",
    "\n",
    "Goal: Build Spark Mlib pipeline to classify whether the tweet contains hate speech or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> Focus is not to build a very accurate classification model but to see how to use any model and return results on streaming data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 2) Predict and Return Results\n",
    "\n",
    "Once we get a new the tweet (and we will do using kafka streaming), \n",
    "we pass the data into the machine learning pipeline we created and return the predicted sentiment from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.streaming import StreamingContext\n",
    "import pyspark.sql.types as tp\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.feature import StopWordsRemover, Word2Vec, RegexTokenizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](images/cuofano.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# init 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/27 16:24:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.60:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>TapDataFrame</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x10fd076d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findspark.find( ) \n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"TapDataFrame\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](http://thejoyofgeek.net/wp-content/uploads/2016/08/robotmask.jpg)\n",
    "[S2E4](http://thejoyofgeek.net/mr-robot-init_1-review-s2e4/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " # Let's Start!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Trainset \n",
    "***SentiTUT*** \n",
    "\n",
    "http://www.di.unito.it/~tutreeb/sentipolc-evalita16/data.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# idtwitter\tsubj\topos\toneg\tiro\tlpos\tlneg\ttop\ttext\n",
    "\n",
    "schema = tp.StructType([\n",
    "    tp.StructField(name= 'id', dataType= tp.StringType(),  nullable= True),\n",
    "    tp.StructField(name= 'subjective',       dataType= tp.IntegerType(),  nullable= True),\n",
    "    tp.StructField(name= 'positive',       dataType= tp.IntegerType(),  nullable= True),\n",
    "    tp.StructField(name= 'negative',       dataType= tp.IntegerType(),  nullable= True),\n",
    "    tp.StructField(name= 'ironic',       dataType= tp.IntegerType(),  nullable= True),\n",
    "    tp.StructField(name= 'lpositive',       dataType= tp.IntegerType(),  nullable= True),\n",
    "    tp.StructField(name= 'lnegative',       dataType= tp.IntegerType(),  nullable= True),\n",
    "    tp.StructField(name= 'top',       dataType= tp.IntegerType(),  nullable= True),\n",
    "    tp.StructField(name= 'text',       dataType= tp.StringType(),   nullable= True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: string, subjective: int, positive: int, negative: int, ironic: int, lpositive: int, lnegative: int, top: int, text: string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the dataset  \n",
    "training_set = spark.read.csv('../spark/dataset/training_set_sentipolc16.csv',\n",
    "                         schema=schema,\n",
    "                         header=True,\n",
    "                         sep=',')\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+--------+--------+------+---------+---------+---+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|id                |subjective|positive|negative|ironic|lpositive|lnegative|top|text                                                                                                                                         |\n",
      "+------------------+----------+--------+--------+------+---------+---------+---+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|122449983151669248|1         |0       |1       |0     |0        |1        |1  |\"Intanto la partita per Via Nazionale si complica. #Saccomanni dice che \"\"mica tutti sono Mario #Monti\"\" http://t.co/xPtNz4X7 via @linkiesta\"|\n",
      "|125485104863780865|1         |0       |1       |0     |0        |1        |1  |False illusioni, sgradevoli realtà Mario Monti http://t.co/WOmMCITs via @AddToAny                                                            |\n",
      "|125513454315507712|1         |0       |1       |0     |0        |1        |1  |False illusioni, sgradevoli realtà #editoriale di Mario Monti sul Corriere della Sera: http://t.co/2jPxX6Jm #rassegna stampa                 |\n",
      "|125524238290522113|1         |0       |1       |0     |0        |1        |1  |Mario Monti: Berlusconi risparmi all'Italia il biasimo per aver causato un disastro #mariomontipremier                                       |\n",
      "|125527933224886272|1         |0       |1       |0     |0        |1        |1  |Mario Monti: Berlusconi risparmi all'Italia il biasimo per aver causato un disastro. I giudizi di Usa e Europa. http://t.co/evXRFF1L         |\n",
      "|125530285164072961|1         |1       |1       |0     |1        |1        |1  |False illusioni, sgradevoli realtà Analisi impeccabile di Mario Monti, e l'ennesimo grido di allarme http://t.co/T5GTgIeE via @AddThis       |\n",
      "|125533343482789889|1         |0       |1       |0     |0        |1        |1  |L'attacco di Mario Monti al governo Berlusconi -False illusioni, sgradevoli realtà Corriere della Sera: http://t.co/h9X8OeQS                 |\n",
      "|125633929217708032|1         |1       |0       |0     |1        |0        |1  |Mario Monti sul Corriere: la fotografia più illuminante sulla delicata situazione attuale http://t.co/YbuNZMOJ                               |\n",
      "|125642756147265536|1         |0       |1       |0     |0        |1        |1  |Le 5 sgradevoli realtà di cui Berlusconi dovrebbe rendersi personalmente conto http://t.co/G3u1iF9n Mario Monti non usa mezzi termini        |\n",
      "|125692702145785856|1         |0       |1       |0     |0        |1        |1  |False illusioni, sgradevoli realtà: http://t.co/4oHbFz1o L'editoriale di Mario Monti sul fallimento di Berlusconi, oggi sul Corriere         |\n",
      "|125695266887184384|1         |0       |1       |1     |0        |1        |1  |Mario Monti: c'è il rischio... di trasformare l'Italia da Stato fondatore in Stato affondatore dell'Unione europea ! http://t.co/z3S1cVFR    |\n",
      "|125838624670490624|1         |0       |1       |1     |0        |1        |1  |Ma a quanta gente DEMOCRATICA rode che la Borsa non ne voglia sapere di continuare a crollare? Povero Mario Monti sara' disperato            |\n",
      "|125949521627840512|1         |0       |1       |0     |0        |1        |1  |Mario Monti: False illusioni, sgradevoli realtà http://t.co/UrlhqFsd Dall'Italia la possibile disintegrazione dell'Unione Europea            |\n",
      "|126527896218107904|1         |0       |1       |0     |0        |1        |1  |@mauryred82 l'ho letto quell'articolo in treno sul CORRIERE DELLA SERA... parole durissime..ed e' MARIO MONTI..un moderato.. SIAM MESSI MALE |\n",
      "|127100968415395841|1         |0       |1       |0     |0        |1        |1  |Ascolti Mario Monti e ti chiedi.. Perché disperdere un capitale e continuare a farsi rappresentare da questi pezzi di merda?! #ottoemezzo    |\n",
      "|127137847491821568|1         |0       |1       |1     |1        |0        |1  |#la7 ma perche' Mario Monti non fa il premier? Che persona competente e per bene!                                                            |\n",
      "|128787344999460865|1         |0       |1       |0     |0        |1        |1  |Perché non ha senso parlare di governo Monti, Casini o Bersani http://t.co/NdAZ1HuW                                                          |\n",
      "|129143970163990528|1         |0       |1       |1     |0        |0        |1  |Mario Monti è conosciuto dal 60% degli intervistati. Che però preferiscono chiamarlo gamberi e zucchine. serena gandhi http://t.co/kNLHGrHU  |\n",
      "|130172208772419585|1         |1       |0       |0     |1        |0        |1  |@riotta sono piu' tranquillo ora :-) buona giornata. Cmq ci vorrebbe Mario Monti                                                             |\n",
      "|130592030031228929|1         |0       |1       |0     |0        |1        |1  |Mario #Monti: La lira non era una moneta strana, ma era il più' delle volte una moneta debole, perche rifletteva caratteristiche dell'Italia |\n",
      "+------------------+----------+--------+--------+------+---------+---------+---+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_set.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|positive|count|\n",
      "+--------+-----+\n",
      "|       1| 2051|\n",
      "|       0| 5359|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#training_set.show(truncate=False)\n",
    "training_set.groupBy(\"positive\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# define stage 1: tokenize the tweet text    \n",
    "stage_1 = RegexTokenizer(inputCol= 'text' , outputCol= 'tokens', pattern= '\\\\W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/27 16:28:40 WARN StopWordsRemover: Default locale set was [en_IT]; however, it was not found in available locales in JVM, falling back to en_US locale. Set param `locale` in order to respect another locale.\n"
     ]
    }
   ],
   "source": [
    "# define stage 2: remove the stop words\n",
    "stage_2 = StopWordsRemover(inputCol= 'tokens', outputCol= 'filtered_words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# define stage 3: create a word vector of the size 100\n",
    "stage_3 = Word2Vec(inputCol= 'filtered_words', outputCol= 'vector', vectorSize= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# define stage 4: Logistic Regression Model\n",
    "model = LogisticRegression(featuresCol= 'vector', labelCol= 'positive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://cdn-images-1.medium.com/max/1600/1*DyD3VP18IV3-lXcKMbyr5w.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline_2e8a1f061128"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup the pipeline\n",
    "pipeline = Pipeline(stages= [stage_1, stage_2, stage_3, model])\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/27 16:31:39 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "22/05/27 16:31:39 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# fit the pipeline model with the training data\n",
    "pipelineFit = pipeline.fit(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.ml.classification.BinaryLogisticRegressionTrainingSummary at 0x107dc5d30>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelSummary=pipelineFit.stages[-1].summary\n",
    "modelSummary \n",
    "# https://spark.apache.org/docs/latest/api/java/org/apache/spark/ml/classification/LogisticRegressionSummary.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7425101214574898"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelSummary.accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](images/accuracy.jpg)\n",
    "[DeepLearningNewsAndMemes](https://www.facebook.com/DeepLearningNewsAndMemes/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------+\n",
      "|text                                                                             |\n",
      "+---------------------------------------------------------------------------------+\n",
      "|False illusioni, sgradevoli realtà Mario Monti http://t.co/WOmMCITs via @AddToAny|\n",
      "+---------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweetDf = spark.createDataFrame([\"False illusioni, sgradevoli realtà Mario Monti http://t.co/WOmMCITs via @AddToAny\"], tp.StringType()).toDF(\"text\")\n",
    "tweetDf.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------+----------+\n",
      "|text                                                                             |tokens                                                                                   |prediction|\n",
      "+---------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------+----------+\n",
      "|False illusioni, sgradevoli realtà Mario Monti http://t.co/WOmMCITs via @AddToAny|[false, illusioni, sgradevoli, realt, mario, monti, http, t, co, wommcits, via, addtoany]|0.0       |\n",
      "+---------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipelineFit.transform(tweetDf).select('text','tokens','prediction').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|text |\n",
      "+-----+\n",
      "|Amore|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweetDf = spark.createDataFrame([\"Amore\"], tp.StringType()).toDF(\"text\")\n",
    "tweetDf.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|tokens |prediction|\n",
      "+-------+----------+\n",
      "|[amore]|1.0       |\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipelineFit.transform(tweetDf).select('tokens','prediction').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/27 16:36:20 ERROR Instrumentation: java.io.IOException: Path ../spark/dataset/model.save already exists. To overwrite it, please use write.overwrite().save(path) for Scala and use write().overwrite().save(path) for Java and Python.\n",
      "\tat org.apache.spark.ml.util.FileSystemOverwrite.handleOverwrite(ReadWrite.scala:683)\n",
      "\tat org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:167)\n",
      "\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.super$save(Pipeline.scala:344)\n",
      "\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$4(Pipeline.scala:344)\n",
      "\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent(events.scala:174)\n",
      "\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent$(events.scala:169)\n",
      "\tat org.apache.spark.ml.util.Instrumentation.withSaveInstanceEvent(Instrumentation.scala:42)\n",
      "\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3(Pipeline.scala:344)\n",
      "\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3$adapted(Pipeline.scala:344)\n",
      "\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n",
      "\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.save(Pipeline.scala:344)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o989.save.\n: java.io.IOException: Path ../spark/dataset/model.save already exists. To overwrite it, please use write.overwrite().save(path) for Scala and use write().overwrite().save(path) for Java and Python.\n\tat org.apache.spark.ml.util.FileSystemOverwrite.handleOverwrite(ReadWrite.scala:683)\n\tat org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:167)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.super$save(Pipeline.scala:344)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$4(Pipeline.scala:344)\n\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent(events.scala:174)\n\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent$(events.scala:169)\n\tat org.apache.spark.ml.util.Instrumentation.withSaveInstanceEvent(Instrumentation.scala:42)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3(Pipeline.scala:344)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3$adapted(Pipeline.scala:344)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.save(Pipeline.scala:344)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpipelineFit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../spark/dataset/model.save\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/pyspark/ml/util.py:226\u001b[0m, in \u001b[0;36mMLWritable.save\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave\u001b[39m(\u001b[38;5;28mself\u001b[39m, path):\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;124;03m\"\"\"Save this ML instance to the given path, a shortcut of 'write().save(path)'.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/pyspark/ml/util.py:177\u001b[0m, in \u001b[0;36mJavaMLWriter.save\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath should be a string, got type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(path))\n\u001b[0;32m--> 177\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/pyspark/sql/utils.py:111\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m py4j\u001b[38;5;241m.\u001b[39mprotocol\u001b[38;5;241m.\u001b[39mPy4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    113\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o989.save.\n: java.io.IOException: Path ../spark/dataset/model.save already exists. To overwrite it, please use write.overwrite().save(path) for Scala and use write().overwrite().save(path) for Java and Python.\n\tat org.apache.spark.ml.util.FileSystemOverwrite.handleOverwrite(ReadWrite.scala:683)\n\tat org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:167)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.super$save(Pipeline.scala:344)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$4(Pipeline.scala:344)\n\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent(events.scala:174)\n\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent$(events.scala:169)\n\tat org.apache.spark.ml.util.Instrumentation.withSaveInstanceEvent(Instrumentation.scala:42)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3(Pipeline.scala:344)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3$adapted(Pipeline.scala:344)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.save(Pipeline.scala:344)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    }
   ],
   "source": [
    "pipelineFit.save(\"../spark/dataset/model.save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+\n",
      "|         threshold|           F-Measure|\n",
      "+------------------+--------------------+\n",
      "|0.9620675430380442|0.017357762777242044|\n",
      "|0.9366308905904482| 0.02399232245681382|\n",
      "|0.9184655155861272| 0.03060736489717838|\n",
      "|0.8988745253950465|0.037178265014299335|\n",
      "|0.8832970125119248| 0.04180522565320665|\n",
      "|0.8693926532522985| 0.05377358490566037|\n",
      "|0.8542836706351302| 0.06015037593984963|\n",
      "|0.8349571094373316| 0.06551240056153486|\n",
      "|0.8181633931500188| 0.06996268656716417|\n",
      "|0.8041191197507951| 0.07438400743840075|\n",
      "|0.7980151682172789| 0.07784986098239109|\n",
      "|0.7841865750917644| 0.08314087759815243|\n",
      "|0.7738372934382455|  0.0892774965485504|\n",
      "|0.7644432556199672| 0.09536909674461257|\n",
      "|0.7538053529686473| 0.10050251256281408|\n",
      "|0.7371259427180132| 0.10473588342440801|\n",
      "|0.7300462850992223| 0.10980036297640654|\n",
      "| 0.717939256094174| 0.11307100859339665|\n",
      "|0.7065777120044586| 0.11541929666366095|\n",
      "|0.6882472680183942| 0.12044943820224718|\n",
      "+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nics/miniforge3/lib/python3.9/site-packages/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Set the model threshold to maximize F-Measure\n",
    "fMeasure = modelSummary.fMeasureByThreshold\n",
    "fMeasure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|    max(F-Measure)|\n",
      "+------------------+\n",
      "|0.4953159598024187|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "maxFMeasure = fMeasure.groupBy().max('F-Measure').select('max(F-Measure)')\n",
    "maxFMeasure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|         threshold|         F-Measure|\n",
      "+------------------+------------------+\n",
      "|0.2457349436145636|0.4953159598024187|\n",
      "+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bestThreshold=fMeasure.where(fMeasure['F-Measure'] == 0.4953159598024187)\n",
    "bestThreshold.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression_73db463d2bde"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.setThreshold(0.2457349436145636)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7425101214574898"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelSummary=pipelineFit.stages[-1].summary\n",
    "modelSummary.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 173:>                                                        (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# fit the pipeline model with the training data\n",
    "pipelineFit = pipeline.fit(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6002699055330635"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelSummary=pipelineFit.stages[-1].summary\n",
    "modelSummary.accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://i.imgflip.com/40mt0s.jpg)\n",
    "[NicsMeme](https://imgflip.com/i/40mt0s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Another Approach: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# define stage 3: create a word vector of the size 100\n",
    "hashingTF = HashingTF(inputCol=\"filtered_words\", outputCol=\"vector\", numFeatures=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# define stage 4: Logistic Regression Model\n",
    "modelNaive =  NaiveBayes(smoothing=1.0, modelType=\"multinomial\",featuresCol= 'vector', labelCol= 'positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# setup the pipeline\n",
    "pipelineNaive = Pipeline(stages= [stage_1, stage_2, hashingTF, modelNaive])\n",
    "\n",
    "# fit the pipeline model with the training data\n",
    "pipelineNaiveFit = pipelineNaive.fit(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipelineModel_aafc48afeb81"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelineNaiveFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+--------+--------+------+---------+---------+---+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|                id|subjective|positive|negative|ironic|lpositive|lnegative|top|                text|              tokens|      filtered_words|              vector|       rawPrediction|         probability|prediction|\n",
      "+------------------+----------+--------+--------+------+---------+---------+---+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|122449983151669248|         1|       0|       1|     0|        0|        1|  1|\"Intanto la parti...|[intanto, la, par...|[intanto, la, par...|(20,[1,2,5,7,8,9,...|[-60.853495557968...|[0.71615635721973...|       0.0|\n",
      "|125485104863780865|         1|       0|       1|     0|        0|        1|  1|False illusioni, ...|[false, illusioni...|[false, illusioni...|(20,[1,2,5,8,9,12...|[-32.016758584080...|[0.71256437318795...|       0.0|\n",
      "|125513454315507712|         1|       0|       1|     0|        0|        1|  1|False illusioni, ...|[false, illusioni...|[false, illusioni...|(20,[1,2,3,4,5,7,...|[-50.605038834543...|[0.76122396467856...|       0.0|\n",
      "|125524238290522113|         1|       0|       1|     0|        0|        1|  1|Mario Monti: Berl...|[mario, monti, be...|[mario, monti, be...|(20,[1,2,3,4,5,8,...|[-38.528212542914...|[0.78979682665815...|       0.0|\n",
      "|125527933224886272|         1|       0|       1|     0|        0|        1|  1|Mario Monti: Berl...|[mario, monti, be...|[mario, monti, be...|(20,[1,2,3,4,5,8,...|[-57.985170261255...|[0.88465000502439...|       0.0|\n",
      "|125530285164072961|         1|       1|       1|     0|        1|        1|  1|False illusioni, ...|[false, illusioni...|[false, illusioni...|(20,[0,1,2,5,6,8,...|[-60.387657883083...|[0.62037949054680...|       0.0|\n",
      "|125533343482789889|         1|       0|       1|     0|        0|        1|  1|L'attacco di Mari...|[l, attacco, di, ...|[l, attacco, di, ...|(20,[1,2,3,5,7,8,...|[-51.363361434018...|[0.85219092176333...|       0.0|\n",
      "|125633929217708032|         1|       1|       0|     0|        1|        0|  1|Mario Monti sul C...|[mario, monti, su...|[mario, monti, su...|(20,[2,4,5,6,7,8,...|[-45.213274592424...|[0.75926105549426...|       0.0|\n",
      "|125642756147265536|         1|       0|       1|     0|        0|        1|  1|Le 5 sgradevoli r...|[le, 5, sgradevol...|[le, 5, sgradevol...|(20,[1,2,3,4,5,6,...|[-61.081004660662...|[0.62377550613351...|       0.0|\n",
      "|125692702145785856|         1|       0|       1|     0|        0|        1|  1|False illusioni, ...|[false, illusioni...|[false, illusioni...|(20,[1,2,3,4,5,7,...|[-55.295901304654...|[0.75916005764850...|       0.0|\n",
      "|125695266887184384|         1|       0|       1|     1|        0|        1|  1|Mario Monti: c'è ...|[mario, monti, c,...|[mario, monti, c,...|(20,[1,2,5,8,9,10...|[-55.372692489681...|[0.78556992305300...|       0.0|\n",
      "|125838624670490624|         1|       0|       1|     1|        0|        1|  1|Ma a quanta gente...|[ma, a, quanta, g...|[ma, quanta, gent...|(20,[1,2,4,8,9,10...|[-60.401217417684...|[0.59411212502712...|       0.0|\n",
      "|125949521627840512|         1|       0|       1|     0|        0|        1|  1|Mario Monti: Fals...|[mario, monti, fa...|[mario, monti, fa...|(20,[0,2,5,8,9,12...|[-51.230167940941...|[0.73660999266030...|       0.0|\n",
      "|126527896218107904|         1|       0|       1|     0|        0|        1|  1|@mauryred82 l'ho ...|[mauryred82, l, h...|[mauryred82, l, h...|(20,[1,2,3,4,5,6,...|[-65.920951738714...|[0.82044496094775...|       0.0|\n",
      "|127100968415395841|         1|       0|       1|     0|        0|        1|  1|Ascolti Mario Mon...|[ascolti, mario, ...|[ascolti, mario, ...|(20,[1,2,3,4,5,8,...|[-58.251628300568...|[0.76336715477402...|       0.0|\n",
      "|127137847491821568|         1|       0|       1|     1|        1|        0|  1|#la7 ma perche' M...|[la7, ma, perche,...|[la7, ma, perche,...|(20,[2,7,8,9,10,1...|[-45.058645264914...|[0.62615088476820...|       0.0|\n",
      "|128787344999460865|         1|       0|       1|     0|        0|        1|  1|Perché non ha sen...|[perch, non, ha, ...|[perch, non, ha, ...|(20,[1,3,4,5,8,9,...|[-38.532165959167...|[0.80671766073653...|       0.0|\n",
      "|129143970163990528|         1|       0|       1|     1|        0|        0|  1|Mario Monti è con...|[mario, monti, co...|[mario, monti, co...|(20,[0,1,2,4,5,6,...|[-55.200690663974...|[0.78352099255760...|       0.0|\n",
      "|130172208772419585|         1|       1|       0|     0|        1|        0|  1|@riotta sono piu'...|[riotta, sono, pi...|[riotta, sono, pi...|(20,[1,2,3,4,7,8,...|[-35.698969071701...|[0.74910366055591...|       0.0|\n",
      "|130592030031228929|         1|       0|       1|     0|        0|        1|  1|Mario #Monti: La ...|[mario, monti, la...|[mario, monti, la...|(20,[0,2,3,5,6,8,...|[-71.332891284446...|[0.61801561896488...|       0.0|\n",
      "+------------------+----------+--------+--------+------+---------+---------+---+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select example rows to display.\n",
    "predictions = pipelineNaiveFit.transform(training_set)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.722132253711201\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"positive\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Yet another one \n",
    "https://towardsdatascience.com/sentiment-analysis-with-pyspark-bc8e83f80c35\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashtf = HashingTF(numFeatures=2**16, inputCol=\"words\", outputCol='tf')\n",
    "idf = IDF(inputCol='tf', outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "model = LogisticRegression(featuresCol= 'features', labelCol= 'positive',maxIter=100)\n",
    "pipeline = Pipeline(stages=[tokenizer, hashtf, idf, model])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/27 16:42:11 WARN DAGScheduler: Broadcasting large task binary with size 1073.9 KiB\n",
      "22/05/27 16:42:11 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:11 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "22/05/27 16:42:11 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "22/05/27 16:42:11 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:11 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:11 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:11 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:11 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:11 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:11 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:11 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:11 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:11 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:11 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:11 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:11 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:11 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:11 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:11 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:11 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:11 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:11 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:12 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:13 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:13 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:13 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:13 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:13 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:13 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:13 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:13 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:13 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:13 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:13 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:13 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:13 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:13 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:13 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:13 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:13 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:13 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:13 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/27 16:42:13 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:13 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:13 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:13 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:13 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:13 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:13 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:13 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:13 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:13 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n",
      "22/05/27 16:42:13 WARN DAGScheduler: Broadcasting large task binary with size 1075.5 KiB\n"
     ]
    }
   ],
   "source": [
    "# fit the pipeline model with the training data\n",
    "pipelineFit = pipeline.fit(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/27 16:42:23 WARN DAGScheduler: Broadcasting large task binary with size 1116.0 KiB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9257759784075573"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelSummary=pipelineFit.stages[-1].summary\n",
    "modelSummary.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = tp.StructType([tp.StructField(\"text\",tp.StringType(),True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------+\n",
      "|text                                                                                                          |\n",
      "+--------------------------------------------------------------------------------------------------------------+\n",
      "|Mario Monti sul Corriere: la fotografia più illuminante sulla delicata situazione attuale http://t.co/YbuNZMOJ|\n",
      "+--------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|       1.0|\n",
      "+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/27 16:43:00 WARN DAGScheduler: Broadcasting large task binary with size 1106.8 KiB\n",
      "22/05/27 16:43:00 WARN DAGScheduler: Broadcasting large task binary with size 1106.8 KiB\n",
      "22/05/27 16:43:00 WARN DAGScheduler: Broadcasting large task binary with size 1106.8 KiB\n"
     ]
    }
   ],
   "source": [
    "tweetDf = spark.createDataFrame([\"Mario Monti sul Corriere: la fotografia più illuminante sulla delicata situazione attuale http://t.co/YbuNZMOJ\"], tp.StringType()).toDF(\"text\")\n",
    "tweetDf.select(\"text\").show(truncate=False)\n",
    "tw2=pipelineFit.transform(tweetDf)\n",
    "tw2.select(\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|text                                                                                                                                 |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Le 5 sgradevoli realtà di cui Berlusconi dovrebbe rendersi personalmente conto http://t.co/G3u1iF9n Mario Monti non usa mezzi termini|\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|       0.0|\n",
      "+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/27 16:43:50 WARN DAGScheduler: Broadcasting large task binary with size 1106.8 KiB\n",
      "22/05/27 16:43:50 WARN DAGScheduler: Broadcasting large task binary with size 1106.8 KiB\n",
      "22/05/27 16:43:50 WARN DAGScheduler: Broadcasting large task binary with size 1106.8 KiB\n"
     ]
    }
   ],
   "source": [
    "tweetDf = spark.createDataFrame([\"Le 5 sgradevoli realtà di cui Berlusconi dovrebbe rendersi personalmente conto http://t.co/G3u1iF9n Mario Monti non usa mezzi termini\"], tp.StringType()).toDF(\"text\")\n",
    "tweetDf.select(\"text\").show(truncate=False)\n",
    "tw2=pipelineFit.transform(tweetDf)\n",
    "tw2.select(\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|text          |\n",
      "+--------------+\n",
      "|Monti mi piace|\n",
      "+--------------+\n",
      "\n",
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|       1.0|\n",
      "+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/27 16:43:57 WARN DAGScheduler: Broadcasting large task binary with size 1106.8 KiB\n",
      "22/05/27 16:43:57 WARN DAGScheduler: Broadcasting large task binary with size 1106.8 KiB\n",
      "22/05/27 16:43:57 WARN DAGScheduler: Broadcasting large task binary with size 1106.8 KiB\n"
     ]
    }
   ],
   "source": [
    "tweetDf = spark.createDataFrame([\"Monti mi piace\"], tp.StringType()).toDF(\"text\")\n",
    "tweetDf.select(\"text\").show(truncate=False)\n",
    "tw2=pipelineFit.transform(tweetDf)\n",
    "tw2.select(\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/27 16:44:04 WARN DAGScheduler: Broadcasting large task binary with size 1116.1 KiB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.971300461118872"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pipelineFit.transform(training_set)\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\",labelCol=\"positive\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|text       |\n",
      "+-----------+\n",
      "|brutte cose|\n",
      "+-----------+\n",
      "\n",
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|       0.0|\n",
      "+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/27 17:45:25 WARN DAGScheduler: Broadcasting large task binary with size 1106.8 KiB\n",
      "22/05/27 17:45:25 WARN DAGScheduler: Broadcasting large task binary with size 1106.8 KiB\n",
      "22/05/27 17:45:25 WARN DAGScheduler: Broadcasting large task binary with size 1106.8 KiB\n"
     ]
    }
   ],
   "source": [
    "tweetDf = spark.createDataFrame([\"brutte cose\"], tp.StringType()).toDF(\"text\")\n",
    "tweetDf.select(\"text\").show(truncate=False)\n",
    "tw2=pipelineFit.transform(tweetDf)\n",
    "tw2.select(\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/22 09:26:14 WARN DAGScheduler: Broadcasting large task binary with size 1110.9 KiB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9257759784075573"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = predictions.filter(predictions.positive == predictions.prediction).count() / float(training_set.count())\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Biblio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* https://www.analyticsvidhya.com/blog/2019/12/streaming-data-pyspark-machine-learning-model/\n",
    "* https://www.kdnuggets.com/2018/02/machine-learning-algorithm-2118.html\n",
    "* https://towardsdatascience.com/sentiment-analysis-using-logistic-regression-and-naive-bayes-16b806eb4c4b\n",
    "* http://www.di.unito.it/~tutreeb/sentipolc-evalita16/data.html\n",
    "* http://www.di.unito.it/~tutreeb/ironita-evalita18/data.html\n",
    "* https://towardsdatascience.com/sentiment-analysis-and-emotion-recognition-in-italian-using-bert-92f5c8fe8a2\n",
    "* https://github.com/charlesmalafosse/open-dataset-for-sentiment-analysis\n",
    "* https://iris.unito.it/retrieve/handle/2318/146318/175020/21_Paper.pdf\n",
    "* https://aperto.unito.it/retrieve/handle/2318/1698302/496918/Sentiment%20analysis%20on%20Italian%20tweets.pdf\n",
    "* https://iopscience.iop.org/article/10.1088/1742-6596/1000/1/012130/pdf\n",
    "* https://towardsdatascience.com/sentiment-analysis-using-logistic-regression-and-naive-bayes-16b806eb4c4b\n",
    "* https://towardsdatascience.com/sentiment-analysis-with-pyspark-bc8e83f80c35\n",
    "* https://dzone.com/articles/streaming-machine-learning-pipeline-for-sentiment\n",
    "* https://databricks.com/wp-content/uploads/2015/10/STEP-3-Sentiment_Analysis.html\n",
    "* https://github.com/P7h/Spark-MLlib-Twitter-Sentiment-Analysis/blob/master/src/main/scala/org/p7h/spark/sentiment/mllib/MLlibSentimentAnalyzer.scala\n",
    "* https://www.researchgate.net/publication/315913579_An_Apache_Spark_Implementation_for_Sentiment_Analysis_on_Twitter_Data\n",
    "* https://medium.com/analytics-vidhya/congressional-tweets-using-sentiment-analysis-to-cluster-members-of-congress-in-pyspark-10afa4d1556e\n",
    "* https://developer.hpe.com/blog/streaming-ml-pipeline-for-sentiment-analysis-using-apache-apis-kafka-spark-and-drill-part-2/\n",
    "* https://dataespresso.com/en/2017/10/24/comparison-between-naive-bayes-and-logistic-regression/#:~:text=Na%C3%AFve%20Bayes%20has%20a%20naive,belonging%20to%20a%20certain%20class.\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": "true",
   "footer": "<div class=\"tap-footer\"> *** Technologies for advanced programming (TAP) - 2022 ***</div>",
   "header": "<div class=\"tap-header\"></div>",
   "scroll": true,
   "theme": "white"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
